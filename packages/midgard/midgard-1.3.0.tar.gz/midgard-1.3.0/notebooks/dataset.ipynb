{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "The Midgard **Dataset** can be used to store data in memory or on disk. If the **Dataset** is saved as file on disk, than the Hierarchical Data Format 5 (HDF5) is applied. HDF5 is a high-performance storage format designed specifically for storing tabular arrays of data. Data or subsets of data can be stored and accessed very efficiently with HDF5. Python supports HDF5 via the **h5py** package, which is designed to work with **NumPy**. \n",
    "\n",
    "The **Dataset** consists of **fields**. Each field is a data array, whereby the number of observations for all fields are the same. The fields can have different kind of data types. Following field datatypes can be defined:\n",
    "\n",
    "- bool\n",
    "- collection\n",
    "- float\n",
    "- position\n",
    "- position_delta\n",
    "- posvel\n",
    "- posvel_delta \n",
    "- sigma\n",
    "- text\n",
    "- time\n",
    "- time_delta\n",
    "\n",
    "For each field datatype exists an method for adding a specific type of data to **Dataset**. These functions are called **add_\\< datatype \\>()**, whereby \\< datatype \\> is a placeholder for the existing field datatypes (e.g. float or time).\n",
    "\n",
    "The figure below illustrates a **Dataset** with different kind of field datatypes, which is saved in memory as an array. The **Dataset** in the memory can be saved as HDF5 file on disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"figures/dataset/dataset_overview.png\", width=1000/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Dataset\n",
    "\n",
    "An example is shown, how to use a Dataset. The first step is to generate an instance of the Dataset class, whereby the size of the Dataset fields has to be defined. Afterwards fields have to be added by defining the field datatype. If necessary the Dataset can be written as file to disk or can be read afterwards again. An example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset package\n",
    "from midgard.data import dataset\n",
    "\n",
    "# Get Dataset instance\n",
    "dset = dataset.Dataset()\n",
    "\n",
    "# Define size of Dataset arrays\n",
    "dset.num_obs = 5  # also possible via dataset.Dataset(num_obs=5)\n",
    "\n",
    "# Add float field to Dataset\n",
    "dset.add_float(name='numbers', val=[1,2,3,4,5])\n",
    "\n",
    "# Two ways to access Dataset 'numbers' field\n",
    "numbers = dset.numbers\n",
    "numbers = dset['numbers']\n",
    "\n",
    "# Access element of Dataset\n",
    "first_number = dset.numbers[0]\n",
    "print(f\"numbers: {numbers}\\nfirst_number: {first_number}\")\n",
    "\n",
    "# Write Dataset on disk as HDF5 file\n",
    "dset.write(file_path='./examples/dataset/numbers.hdf5')\n",
    "\n",
    "# Read Dataset from HDF5 file\n",
    "dset2 = dataset.Dataset()\n",
    "dset2 = dset2.read(file_path='./examples/dataset/numbers.hdf5')\n",
    "print(f\"\\ndset:\\n{dset}\\n\\ndset2:\\n{dset2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset attributes and methods\n",
    "\n",
    "General attributes of a **Dataset** are described in the table below. Hereby should be noted, that additional attributes can be added. This additional attributes are called **fields**, which can be added to the **Dataset** with the command **add_\\< datatype \\>()** as mentioned above. How to use **add_\\< datatype \\>()** will be described in section _Field datatypes_ for each field data type.\n",
    "\n",
    "| Attribute   | Description                                                           |\n",
    "| :---------- | :-------------------------------------------------------------------- |\n",
    "| default_field_suffix      | **TODO**                                                |\n",
    "| fields      | Names of fields in the dataset                                        |\n",
    "| meta        | Dictionary with meta information of data                              |\n",
    "| num_obs     | Number of observations in dataset                                     |\n",
    "| plot_fields | Names of fields in the dataset that would make sense to plot          |\n",
    "| vars        | Dictionary with variables used for example to generate dataset file name  |\n",
    "| version     | Dataset and Midgard version                                           |\n",
    "\n",
    "The table below describes shortly the **Dataset** methods.\n",
    "\n",
    "| Method      | Description                                                           |\n",
    "| :---------- | :-------------------------------------------------------------------- |\n",
    "| add_\\< datatype \\>     | For each field datatype exists an method for adding a specific type of data to Dataset. These functions are called add_< datatype >(), whereby < datatype > is a placeholder for the existing field datatypes (e.g. float or time).|\n",
    "| apply       | Apply a function to a field                                           |\n",
    "| as_dataframe| Return a representation of the dataset as a Pandas DataFrame          |\n",
    "| as_dict     | Return a representation of the dataset as a dictionary                |\n",
    "| count       | Count the number of unique values in a field                          |  \n",
    "| difference  | Compute the difference between two datasets: self - other             |\n",
    "| extend      | Add observations from another dataset to the end of this dataset      |\n",
    "| filter      | Filter observations                                                   |\n",
    "| from_dict   | Convert a simple data dictionary to a dataset                         |\n",
    "| mean        | Calculate mean of a field                                             |\n",
    "| merge_with  | Merge in observations from other datasets. Note that this is quite strict in terms of which datasets can extend each other. They must have exactly the same tables. Tables containing several independent fields (e.g. float, text) may have different fields, in which case fields from both datasets are included. If a field is only defined in one dataset, it will get `empty` values for the observations in the dataset it is not defined. |\n",
    "| num         | Number of observations satisfying the filters                         |\n",
    "| plot_values | Return values of a field in a form that can be plotted                |\n",
    "| read        | Read a dataset from file                                              |\n",
    "| rms         | Calculate Root Mean Square of a field                                 |\n",
    "| std         | Calculate the standard deviation of a field                           |\n",
    "| subset      | Remove observations from all fields based on index                    |\n",
    "| unique      | List unique values of a given field                                   |\n",
    "| unit        | Unit for values in a given field (e.g. meter)                                     |\n",
    "| unit_short  | Short description of unit for values in a given field (e.g. m)  |\n",
    "| update_from | Transfers dataset fields from other Dataset to this Dataset. This will not create a copy of the data in the other Dataset |\n",
    "| write       | Write a dataset to file                                               |\n",
    "| unique      | List unique values of a given field                                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Field datatypes\n",
    "\n",
    "The field datatypes are described in this section and how to add them to a Dataset.\n",
    "\n",
    "### bool\n",
    "\n",
    "**bool** field consists of NumPy array with boolean values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset package\n",
    "from midgard.data import dataset\n",
    "\n",
    "# Get Dataset instance\n",
    "dset = dataset.Dataset(num_obs=5)\n",
    "\n",
    "# Add bool field to Dataset by defining unit of field elements\n",
    "dset.add_bool(name='index', val=[True, False, True, True, False])\n",
    "\n",
    "# Access bool field 'index'\n",
    "print(f\"Field 'index': {dset.index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### float\n",
    "\n",
    "**float** field consists of NumPy array with float values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset package\n",
    "from midgard.data import dataset\n",
    "\n",
    "# Get Dataset instance\n",
    "dset = dataset.Dataset(num_obs=5)\n",
    "\n",
    "# Add float field to Dataset by defining unit of field elements\n",
    "dset.add_float(name='numbers', val=[1,2,3,4,5], unit='meter')\n",
    "\n",
    "# Access float field 'numbers'\n",
    "print(f\"Field 'numbers': {dset.numbers}\")\n",
    "\n",
    "# Print unit of float field 'numbers'\n",
    "print(f\"Unit of field 'numbers': {dset.unit('numbers')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### position\n",
    "\n",
    "**position** field consists of PositionArray arrays. **position** fields can be initialized with following **systems**:\n",
    "\n",
    "- trs: terrestrial reference system with unit [m, m , m]\n",
    "- llh: latitude, longitude and height with unit [rad, rad, m]\n",
    "\n",
    "The position field has to be initialized with the correct unit depending on the chosen **system**. The unit has to be **(meter, meter, meter)** for **trs** system or **(radian, radian, meter)** for **llh** system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NumPy package\n",
    "import numpy as np\n",
    "\n",
    "# Import Dataset package\n",
    "from midgard.data import dataset\n",
    "\n",
    "# Get Dataset instance\n",
    "dset = dataset.Dataset(num_obs=2)\n",
    "\n",
    "# Add position field to Dataset\n",
    "val = np.array([[100, 100, 100], [200, 200, 200]])\n",
    "dset.add_position(name='pos', val=val, system='trs')\n",
    "\n",
    "# Access position field 'pos'\n",
    "print(f\"Field 'pos' in 'trs' system: {dset.pos}\")\n",
    "\n",
    "# Print unit of position field 'pos'\n",
    "print(f\"Unit of field 'pos' in 'trs' system: {dset.unit('pos')}\")\n",
    "      \n",
    "# Dataset field can be converted from terrestrial reference system to\n",
    "# latitude, longitude and height\n",
    "print(f\"\\nField 'pos' in 'llh' system: {dset.pos.llh}\")\n",
    "print(f\"Unit of field 'pos' in 'llh' system: {dset.unit('pos.llh')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: More about **Position** class objects functionality can be found in jupyter notebook **./midgard/documents/notebooks/position.ipynb**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### posvel\n",
    "\n",
    "**posvel** field consists of PosVelArray arrays. **posvel** fields can be initialized with following **systems**:\n",
    "\n",
    "- kepler: Kepler elements (a, e, i, Omega, omega, E) with unit [m, - , rad, rad, rad, rad]\n",
    "- trs: terrestrial reference system (x, y, z, vx, vy, vz) with unit [m, m , m, m/s, m/s, m/s]\n",
    "\n",
    "The posvel field has to be initialized with the correct unit depending on the chosen **system**. The unit has to be **(m, - , rad, rad, rad, rad)** for **kepler** and **(m, m, m, m/s, m/s, m/s)** for **trs** system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NumPy package\n",
    "import numpy as np\n",
    "\n",
    "# Import Dataset package\n",
    "from midgard.data import dataset\n",
    "\n",
    "# Get Dataset instance\n",
    "dset = dataset.Dataset(num_obs=2)\n",
    "\n",
    "# Add position field to Dataset\n",
    "val = np.array([[15095082.616, -16985925.155, 18975783.780,\n",
    "                     1814.893,      -587.648,    -1968.334,\n",
    "                ], \n",
    "                [13831647.196, 24089264.569, 10227973.970,\n",
    "                     -705.078,     -745.436,     2708.633,\n",
    "      ]])\n",
    "dset.add_posvel(name='posvel', val=val, system='trs')\n",
    "\n",
    "# Access posvel field 'posvel'\n",
    "print(f\"Field 'posvel' in 'trs' system: {dset.posvel}\")\n",
    "\n",
    "# Print unit of posvel field 'posvel'\n",
    "print(f\"Unit of field 'posvel' in 'trs' system: {dset.unit('posvel')}\")\n",
    "      \n",
    "# Dataset field can be converted from terrestrial reference system to\n",
    "# Kepler elements\n",
    "print(f\"\\nField 'posvel' in 'kepler' system: {dset.posvel.kepler}\")\n",
    "print(f\"Unit of field 'posvel' in 'kepler' system: {dset.unit('posvel.kepler')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: More about **PosVel** class objects functionality can be found in jupyter notebook **./midgard/documents/notebooks/position.ipynb**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text\n",
    "\n",
    "**text** field consists of numpy arrays and can be initialized as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset package\n",
    "from midgard.data import dataset\n",
    "\n",
    "# Get Dataset instance\n",
    "dset = dataset.Dataset(num_obs=5)\n",
    "\n",
    "# Add text field to Dataset\n",
    "dset.add_text(\n",
    "            name=\"satellite\",\n",
    "            val=[\"E01\", \"E02\", \"E05\", \"G01\", \"G02\"],\n",
    ")\n",
    "\n",
    "# Access text field\n",
    "print(f\"Field 'satellite': {dset.satellite}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time\n",
    "\n",
    "**time** field consists of Time object arrays. The time **scale** and **format** has to be specified by initialization **time** fields in dataset. **time** fields can be initialized with different kind of time **scales** and **formats**. What kind of time scales and formats exists and more about ***Time** class, is described in jupyter notebook **./midgard/documents/notebooks/time.ipynb**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libary import\n",
    "from datetime import datetime\n",
    "\n",
    "# Import Dataset package\n",
    "from midgard.data import dataset\n",
    "\n",
    "# Get Dataset instance\n",
    "dset = dataset.Dataset(num_obs=2)\n",
    "\n",
    "# Add time field to Dataset by defining time scale and format\n",
    "dset.add_time(\n",
    "            name=\"time\",\n",
    "            val=[datetime(2019,2,1), datetime(2019,2,2)],\n",
    "            scale=\"utc\",\n",
    "            fmt=\"datetime\",\n",
    ")\n",
    "\n",
    "# Access time field\n",
    "print(f\"Field 'time': {dset.time}\")\n",
    "\n",
    "# Print time scale and format of time field\n",
    "print(f\"Format: {dset.time.fmt}\")\n",
    "print(f\"Scale: {dset.time.scale}\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
