Metadata-Version: 2.1
Name: bardi
Version: 0.2.1
Summary: A flexible machine learning data pre-processing pipeline framework.
Author: Oak Ridge National Laboratory
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: License :: OSI Approved :: MIT License
Requires-Python: >=3.8.0
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: duckdb ==0.8.0
Requires-Dist: gensim >=4.1.2
Requires-Dist: numpy >=1.21.5
Requires-Dist: pandas >=1.4.4
Requires-Dist: polars >=0.19.8
Requires-Dist: pyarrow >=12.0.1
Requires-Dist: setuptools >=61.0


# bardi
**bardi** - Generalized Automatic Data Ingestion pipeline is a data pre-processing toolkit for the NCI project. With bardi you are able to swiftly construct personalized data preprocessing pipeline tailored to your needs.



Installation
==================
At this stage bardi can be installed via pip into your favorite conda from the wheel file in a shared location:

``pip install /mnt/nci/scratch/packages/bardi-0.2.0-py3-none-any.whl``

Documentation
============================
* [Documentation Link](file:////mnt/nci/scratch/bardi/docs/build/html/index.html)

Tutorial and Example Scripts
============================

* [bardi Run Scripts Repo](https://ncigitlab01.repd.ornlkdi.org/nci/bardi-run-scripts)
* [bardi GitLab](https://ncigitlab01.repd.ornlkdi.org/nci/bardi)

Key Features
============
* **Efficiency** - with power of Polars and multithreading, bardi ensures rapid transformation of even large datasets.
* **Modularity** - designed with component-based architecture, users can integrate individual modules based on their specific needs. Each module (normalizer, pre-tokenizer, splitter etc.) operates as individual unit.
* **Extendibility** - bardi's design allows for seamless integration of new modules and methods.


