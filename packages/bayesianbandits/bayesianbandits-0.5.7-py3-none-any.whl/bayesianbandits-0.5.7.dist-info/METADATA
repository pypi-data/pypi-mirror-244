Metadata-Version: 2.1
Name: bayesianbandits
Version: 0.5.7
Summary: A Pythoic microframework for Multi-Armed Bandit algorithms.
Author: Rishi Kulkarni
Author-email: rishi@kulkarni.science
Requires-Python: >=3.9,<3.12
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Dist: scikit-learn (>=1.2.0)
Requires-Dist: scipy (>=1.11.0,<2.0.0)
Requires-Dist: typing-extensions (>=4.8.0,<5.0.0)
Description-Content-Type: text/markdown

# `bayesianbandits`

bayesianbandits is a Pythonic framework for building agents to maximize rewards in multi-armed bandit (MAB) problems. These agents can handle a number of MAB subproblems, such as contextual, restless, and delayed reward bandits.

Building an agent is as simple as defining arms and using the necessary decorators. For example, to create an agent for a Bernoulli bandit:

```python
import numpy as np

from bayesianbandits import Bandit, Arm, epsilon_greedy, DirichletClassifier

def reward_func(x):
    return np.take(x, 0, axis=-1)

clf = DirichletClassifier({"yes": 1.0, "no": 1.0})
policy = epsilon_greedy(0.1)

class Agent(Bandit, learner=clf, policy=policy):
    arm1 = Arm("action 1", reward_func)
    arm2 = Arm("action 2", reward_func)

agent = Agent()

agent.pull() # receive some reward
agent.update("yes") # update with observed reward

```

## Getting Started

Install this package from PyPI.

```
pip install -U bayesianbandits
```

## Usage

Check out the [documentation](https://bayesianbandits.readthedocs.io/en/latest/) for examples and an API reference.

