{
  "results": {
    "agi_eval-aqua-rat": {
      "acc": 0.2795275590551181,
      "acc_stderr": 0.02821374533845074
    },
    "agi_eval-gaokao-biology": {
      "acc": 0.19523809523809524,
      "acc_stderr": 0.027418446398346893
    },
    "agi_eval-gaokao-chemistry": {
      "acc": 0.24154589371980675,
      "acc_stderr": 0.029821595334353794
    },
    "agi_eval-gaokao-chinese": {
      "acc": 0.24390243902439024,
      "acc_stderr": 0.027435567505267607
    },
    "agi_eval-gaokao-english": {
      "acc": 0.5751633986928104,
      "acc_stderr": 0.028304576673141107
    },
    "agi_eval-gaokao-geography": {
      "acc": 0.35175879396984927,
      "acc_stderr": 0.03393580874720542
    },
    "agi_eval-gaokao-history": {
      "acc": 0.4723404255319149,
      "acc_stderr": 0.03263597118409769
    },
    "agi_eval-gaokao-mathqa": {
      "acc": 0.2706552706552707,
      "acc_stderr": 0.023748744034266786
    },
    "agi_eval-logiqa-en": {
      "acc": 0.23963133640552994,
      "acc_stderr": 0.01674276693510143
    },
    "agi_eval-logiqa-zh": {
      "acc": 0.25806451612903225,
      "acc_stderr": 0.017162894755127077
    },
    "agi_eval-lsat-ar": {
      "acc": 0.21739130434782608,
      "acc_stderr": 0.027256850838819964
    },
    "agi_eval-lsat-lr": {
      "acc": 0.22745098039215686,
      "acc_stderr": 0.018580099622603333
    },
    "agi_eval-lsat-rc": {
      "acc": 0.26022304832713755,
      "acc_stderr": 0.02680130130545777
    },
    "agi_eval-sat-en": {
      "acc": 0.44660194174757284,
      "acc_stderr": 0.03472179658263948
    },
    "agi_eval-sat-en-without-passage": {
      "acc": 0.3592233009708738,
      "acc_stderr": 0.033508784506087796
    },
    "agi_eval-sat-math": {
      "acc": 0.3,
      "acc_stderr": 0.03096617686426667
    }
  },
  "versions": {
    "agi_eval-aqua-rat": 0,
    "agi_eval-gaokao-biology": 0,
    "agi_eval-gaokao-chemistry": 0,
    "agi_eval-gaokao-chinese": 0,
    "agi_eval-gaokao-english": 0,
    "agi_eval-gaokao-geography": 0,
    "agi_eval-gaokao-history": 0,
    "agi_eval-gaokao-mathqa": 0,
    "agi_eval-logiqa-en": 0,
    "agi_eval-logiqa-zh": 0,
    "agi_eval-lsat-ar": 0,
    "agi_eval-lsat-lr": 0,
    "agi_eval-lsat-rc": 0,
    "agi_eval-sat-en": 0,
    "agi_eval-sat-en-without-passage": 0,
    "agi_eval-sat-math": 0
  },
  "config": {
    "model": "hf-causal-experimental",
    "model_args": "pretrained=/home/sdk_models/xverse_13b,dtype='bfloat16',trust_remote_code=True,use_accelerate=False,peft=/home/finetuned_models/my_xverse_model",
    "num_fewshot": 0,
    "batch_size": 2,
    "batch_sizes": [],
    "device": "cuda:7",
    "no_cache": true,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {},
    "cost_time": "0:54:43.231971",
    "model_name": "xverse_13b"
  }
}