Metadata-Version: 2.1
Name: neuranet
Version: 0.0.1
Summary: NeuraNET Python API library
Author: Dark25 (Ruben Roy)
Author-email: me@ruben-roy.com
Keywords: ai,machine learning,neuranet
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Description-Content-Type: text/markdown
Requires-Dist: requests


# üåê NeuraNET Python API library



The Official NeuraNET Python Library



---



## üõ† Installation



To get started with the library, simply run the following command:



```bash

pip install neuranet

```



## üí¨ Chat Usage

Using the Chat AIs library is straightforward. Below is an example of a conversation:

```python

import neuranet



api_key = "YOUR_API_KEY_HERE"

mode = 'chat'

client = neuranet.client(api_key, mode)



# Set up the conversation history and model

conversation_history = [

    {"sender": "instruct", "content": "You are a helpful assistant."},

    {"sender": "user", "content": "Hello."},

    {"sender": "assistant", "content": "Hello, how can I assist you?"},

    {"sender": "user", "content": "How are you?"}

]



model = "nlite"  # options: nlite, npro, npro-vision



# Get the response

try:

    response = client.generate(conversation_history, model)

    print(response)

except Exception as e:

    print(f"An error occurred: {e}")

```



## üé® Image Usage

Using the Image generation AIs library is straightforward. Below is an example of a conversation:

```python

import neuranet



api_key = "YOUR_API_KEY_HERE"

mode = 'image'

client = neuranet.client(api_key, mode)

model = "vinci-mini" # options: vinci-mini, vinci-max



prompt = "A large oak tree"



response = client.generate(prompt, model)

print(response)

```

