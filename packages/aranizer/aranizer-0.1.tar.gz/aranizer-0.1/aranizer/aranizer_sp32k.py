
from transformers import PreTrainedTokenizerFast

def get_tokenizer():
    return PreTrainedTokenizerFast(tokenizer_file="C:/Users/Lenovo/Desktop/aranizer/aranizer/sentence peice tokenizers/SP_tokenizer_32.0K.json")


